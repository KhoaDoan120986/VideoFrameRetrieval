{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name='ViT-H-14-quickgelu',\n",
    "    pretrained='dfn5b',\n",
    "    device=device\n",
    ")\n",
    "model.eval().cuda()\n",
    "\n",
    "output_dir = '/content/drive/MyDrive/AIC/features'    # Save 1 .npy per image\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/content/drive/MyDrive/AIC/keyframes\"\n",
    "image_paths = sorted(glob(f\"{root_dir}/**/*.jpg\", recursive=True))\n",
    "print(f\"Found {len(image_paths)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "folder_to_images = defaultdict(list)\n",
    "for img_path in image_paths:\n",
    "    folder_to_images[os.path.dirname(img_path)].append(img_path)\n",
    "\n",
    "for folder_path, image_files in tqdm(folder_to_images.items(), desc=\"Processing folders\"):\n",
    "    # Create matching output subfolder\n",
    "\n",
    "    rel_path = os.path.relpath(folder_path, root_dir)\n",
    "    save_folder = os.path.join(output_dir, rel_path)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    # Sort image paths for consistent processing\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(image_files), batch_size):\n",
    "        batch_files = image_files[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        valid_files = []\n",
    "\n",
    "        for img_path in batch_files:\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image_tensor = preprocess(image)\n",
    "                batch_images.append(image_tensor)\n",
    "                valid_files.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "        if not batch_images:\n",
    "            continue\n",
    "\n",
    "        # Encode features\n",
    "        input_tensor = torch.stack(batch_images).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = model.encode_image(input_tensor)\n",
    "            features = features / features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Save each feature with same relative path\n",
    "        for img_path, feat in zip(valid_files, features):\n",
    "            rel_img_path = os.path.relpath(img_path, root_dir)\n",
    "            save_path = os.path.join(output_dir, os.path.splitext(rel_img_path)[0] + '.npy')\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            np.save(save_path, feat.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
